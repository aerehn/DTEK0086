{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "App5: Sleep stage classification using electromyography and electro-oculography .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOAuJ7m94RAYX5VbwAMxZpq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aerehn/DTEK0086/blob/main/App5_Sleep_stage_classification_using_electromyography_and_electro_oculography_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DTEK0086 Biosignal Analytics\n",
        "#Sleep stage classification using electromyography and electro-oculography"
      ],
      "metadata": {
        "id": "3CR0w5z01vYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Background\n",
        "Sleep can be divided\n",
        "into distinct categories, including rapid eye movement (REM) sleep and non\n",
        "-\n",
        "rapid eye movement (NREM) sleep. In REM sleep, the eyes move rapidly from side to side, \n",
        "breathing becomes faster and irregular, and heart rate and blood pressure increase to near w\n",
        "aking \n",
        "levels [1].  REM sleep is essential for \n",
        "healthy emotion regulation\n",
        ". NREM sleep consists of light \n",
        "sleep and deep sleep. Both light and deep sleep are essential for various \n",
        "processes\n",
        "in the body. The \n",
        "sleep stages can be measured using the \n",
        "polysomnograp\n",
        "hy\n",
        "method, containing e\n",
        "lectromyography\n",
        "(EMG), e\n",
        "lectrooculography\n",
        "(EOG), and\n",
        "electroencephalography\n",
        ". Facial EMG shows differences \n",
        "between the sleep stages. EOG is a technique to collect the electrical activity of the eye’s muscles. It \n",
        "can also be used to tr\n",
        "ack eye movements."
      ],
      "metadata": {
        "id": "Y12aLxOL1mtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Objective\n",
        "The objective of this project is to\n",
        "perform\n",
        "sleep stage\n",
        "classification leveraging features derived from\n",
        "EOG and EMG\n",
        "signals.\n",
        "U\n",
        "sing machine learning\n",
        ", y\n",
        "ou need to\n",
        "differentiate the\n",
        "records\n",
        "into t\n",
        "hree\n",
        "classes: i.e.,\n",
        "awake, REM, and NREM. \n",
        "The analysis should be done in Python\n",
        "(more details in \n",
        "the \n",
        "Instruction Section)\n",
        ". \n",
        "For this\n",
        "course project, you need to:\n",
        "1.\n",
        "S\n",
        "ubmit \n",
        "your\n",
        "Python \n",
        "script\n",
        "and \n",
        "your\n",
        "report of the observations, graphs, and conclusions \n",
        "made upon analyzing the gi\n",
        "ven signal\n",
        "s. \n",
        "It is suggested to submit a J\n",
        "upyter \n",
        "N\n",
        "otebook\n",
        "file, \n",
        "including your code and report\n",
        ". \n",
        "2.\n",
        "Give a 20\n",
        "-\n",
        "minute presentation about your work. Your presentation should include\n",
        "a \n",
        "description of\n",
        "a.\n",
        "T\n",
        "he problem and the biosignal\n",
        "s\n",
        "b.\n",
        "The steps in your analysis: e.\n",
        "g., what pre\n",
        "-\n",
        "processing method\n",
        "s\n",
        "you use, which \n",
        "features you extract, which machine\n",
        "-\n",
        "learning algorithm\n",
        "s\n",
        "you use\n",
        "c.\n",
        "The results that you obtain\n",
        ": e.g., \n",
        "the \n",
        "accur\n",
        "acy of two machine learning methods\n",
        "d.\n",
        "Your evaluation and conclusion on the findings and methods"
      ],
      "metadata": {
        "id": "_qNVl_n81bAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data collection setup\n",
        "The\n",
        "single\n",
        "-\n",
        "channel\n",
        "EOG \n",
        "was\n",
        "measured from the left side\n",
        "of the face\n",
        "(referenced to the contralateral \n",
        "ear lobe). The \n",
        "single\n",
        "-\n",
        "channel \n",
        "EMG was \n",
        "collected\n",
        "from\n",
        "the chin. \n",
        "The signals\n",
        "were measured in \n",
        "microvolts with \n",
        "the \n",
        "sampling frequency of 200 \n",
        "Hz. \n",
        "The data \n",
        "annotations were\n",
        "performed by human \n",
        "experts. \n",
        "The data is extracted from the Physionets \n",
        "You Snooze You Win\n",
        "challenge\n",
        "database \n",
        "(\n",
        "challenge\n",
        "-\n",
        "2018\n",
        ")"
      ],
      "metadata": {
        "id": "4CuOV4nY1t1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Structure of the data\n",
        "The proje\n",
        "ct includes the records of 100 subjects (i.e., 80 for training and 20 for test). \n",
        "There are 4\n",
        "-\n",
        "9 \n",
        "records for each subject.\n",
        "Each record (i.e., file) consists of one minute of EOG and EMG signals, \n",
        "and it corresponds t\n",
        "o the awake, REM, or NREM stage\n",
        ".\n",
        "The datase\n",
        "t includes separate “Train” and \n",
        "“Test” folders. The folders contain three subfolders \n",
        "as “awake\n",
        ",”\n",
        "“rem\n",
        ",\n",
        "” and “nonrem\n",
        ".\n",
        "” Each record \n",
        "is saved as a CSV file, including two columns corresponding to the EOG and EMG\n",
        "signals\n",
        ". The \n",
        "filename includes the event number\n",
        "and the subject number. For example, 100 is the event number, \n",
        "and 61 is the subject number in “100_subj_61.csv.”"
      ],
      "metadata": {
        "id": "pmoKkx3u2OKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instruction\n",
        "For the analysis, you should:\n",
        "1. Use pre-processing techniques (such as filtering) if necessary.\n",
        "2. Extract relevant time-domain and frequency-domain features from the EOG and EMGsignals (e.g., summary statistics, RMS value, and resonance frequency).\n",
        "3. Standardize your data: i.e., use the mean and standard deviation of the training data to standardize the training data and the test data.\n",
        "4. Select two supervised machine learning algorithms and train two classifiers using the training set. Each classifier should predict 0 for “awake”, 1 for “rem”, or 2 for “nonrem”.\n",
        "5. Compare the two classifiers by evaluating the results using the test set. \n",
        "  - Obtain the confusion matrix, accuracy, precision, recall, and F1-score. These can be calculated from the predicted and true values. Hint: You can utilize packages such as scipy, tsfresh, and tsfel for the pre-processing and feature-extraction steps, and packages such as scikit-learn for the machine-\n",
        "learning step.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "656grFYH2ODH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas"
      ],
      "metadata": {
        "id": "ryE4Aku66W29"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}